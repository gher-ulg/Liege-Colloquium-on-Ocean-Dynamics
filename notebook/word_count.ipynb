{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a file to generate the [`Wordle`](https://gher-ulg.github.io/Liege-Colloquium/topicwordle.html) using the list of topics (file [topic.md](https://github.com/gher-ulg/gher-ulg.github.io/blob/master/Liege-Colloquium/topics.md))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import operator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File to read titles from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"/home/ctroupin/ULiege/gher-ulg.github.io/Liege-Colloquium/topics.md\"\n",
    "jsonfile = \"../data/topicsWordle.js\"\n",
    "jsonfile2 = \"/home/ctroupin/ULiege/gher-ulg.github.io/data/topicsWordle.js\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = []\n",
    "with open(datafile, \"r\") as f:\n",
    "    for lines in f:\n",
    "        # Split line with | as separator\n",
    "        topic = lines.split(\"|\")[2]\n",
    "        # Convert to lower case\n",
    "        topic = [x.lower() for x in topic.split()]\n",
    "        # Remove final 's' (assuming it's plural)\n",
    "        # topic = [x.rstrip()[:-1] if (x.rstrip()[-1] == \"s\") else x.rstrip() for x in topic]\n",
    "        # Add to list\n",
    "        topiclist.extend(topic)\n",
    "# Convert list to string\n",
    "wordstring = \" \".join(topiclist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation and common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(wordstring):\n",
    "    \n",
    "    punctuation = [\":\", \".\", \"–\", '\"', \",\", \"'\"]\n",
    "\n",
    "    removelist = [\"\\n\", \"the\", \"in\", \"a\", \"of\", \"les\",\n",
    "                  \"from\" \"le\", \"à\", \"but\",\n",
    "                  \"and\",\"to\", \"for\", \"at\", \"on\", \n",
    "                  \"no\", \"specific\", \"topic\", \"identifiable\", \"contents\",\n",
    "                  \"several\", \"papers\", \"related\", \"easily\"\n",
    "                  \"contents\"]\n",
    "\n",
    "    substdict = {\"l’océan\": \"ocean\",\n",
    "                  \"from\": \" \",\n",
    "                  \"équations\": \"equations\",\n",
    "                  \"mesoscale/synoptic\": \"mesoscale synoptic\",\n",
    "                  \"modeling\": \"modelling\", \"no specific topic\": \" \",\n",
    "                  \"sub-mesoscale\": \"submesoscale\", \n",
    "                  \"hydrodynamically\": 'hydrodynamics', \n",
    "                  \"hydrodynamical\": 'hydrodynamics', \n",
    "                  \"hydrodynamiques\": 'hydrodynamics', \n",
    "                  \"hydrodynamic\": 'hydrodynamics', \n",
    "                  \"seas\": \"sea\", \"changes\": \"change\",\n",
    "                  \"waters\": \"water\", \n",
    "                  \"ecosystems\": \"ecosystem\",\n",
    "                  \"estuarine\": \"estuaries\",\n",
    "                  \"applicable\": \"applicable\",\n",
    "                  \"tracers\": \"tracer\",\n",
    "                  \"models\": \"modelling\",\n",
    "                  \"re³-visited\": \"revisited\",\n",
    "                  \"re-revisited\": \"revisited\",\n",
    "                  \"environmental\": \"environments\",\n",
    "                  \"remote sensing\": \"remote-sensing\",\n",
    "                  \"bio-geo-chemical\": \"biogeochemical\",\n",
    "                  \"analyses\": \"analysis\",\n",
    "                  \"interaction\": \"interactions\",\n",
    "                  \"prediction\": \"predictions\"\n",
    "                   }\n",
    "\n",
    "    for symbols in punctuation:\n",
    "        wordstring = wordstring.replace(symbols, ' ')\n",
    "    for words in removelist:\n",
    "        wordstring = re.sub(r\"\\b{}\\b\".format(words), ' ', wordstring)\n",
    "    for oldvalue, newvalue in substdict.items():\n",
    "        wordstring = re.sub(r\"{}\\b\".format(oldvalue), newvalue, wordstring)\n",
    "        \n",
    "    return wordstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count word frequency and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "worddict = Counter(wordstring.split())\n",
    "sortedworddict = sorted(worddict.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the dictionary to json\n",
    "We should get something like this: \n",
    "```\n",
    "var words = [\n",
    "  {text: 'have', size: 102},\n",
    "  {text: 'Oliver', size: 47},\n",
    "  {text: 'say', size: 46},\n",
    "  {text: 'said', size: 36}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonfile, \"w\") as jf:\n",
    "    jf.write(\"var words = [\\n\")\n",
    "    for lines in sortedworddict:\n",
    "        jf.write(\"\".join((\"\\t{text: '\", lines[0], \"', size: \", str(lines[1]), \"},\\n\")))\n",
    "    jf.write(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dictionary with the years for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clqdict = {}\n",
    "with open(datafile, \"r\") as f:\n",
    "    for lines in f:\n",
    "        # Split line with | as separator\n",
    "        year = int(lines.split(\"|\")[1])\n",
    "        topic = lines.split(\"|\")[2]\n",
    "        \n",
    "        for wordstring in topic.split():\n",
    "            # Convert to lower case\n",
    "            wordstring = wordstring.lower()\n",
    "            \n",
    "            for symbols in punctuation:\n",
    "                wordstring = wordstring.replace(symbols, ' ')\n",
    "            for words in removelist:\n",
    "                wordstring = re.sub(r\"\\b{}\\b\".format(words), ' ', wordstring)\n",
    "            for oldvalue, newvalue in substdict.items():\n",
    "                wordstring = re.sub(r\"{}\\b\".format(oldvalue), newvalue, wordstring)\n",
    "            \n",
    "            for w in wordstring.split():\n",
    "                if w not in removelist:\n",
    "                    if w in clqdict.keys():\n",
    "                        clqdict[w].insert(0, year)\n",
    "                    else:\n",
    "                        clqdict[w] = [year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dictionary to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written file /home/ctroupin/ULiege/gher-ulg.github.io/data/topicsWordle.js\n"
     ]
    }
   ],
   "source": [
    "with open(jsonfile2, \"w\") as jf:\n",
    "    jf.write(\"var words = [\\n\")\n",
    "    jf.write(\"\\t{text: 'colloquium', size: 102, yearlist: '1969-2018'},\\n\")\n",
    "    for k, v in clqdict.items():\n",
    "        jf.write(\"\".join((\"\\t{text: '\", k, \"', size: \", str(len(v)), \", yearlist: \", str(v),\"},\\n\")))\n",
    "    jf.write(\"]\")\n",
    "print(\"Written file {}\".format(jsonfile2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting by decade\n",
    "We will create a dictionary where the keys are the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicdict = {}\n",
    "with open(datafile, \"r\") as f:\n",
    "    for lines in f:\n",
    "        year = int(lines.split(\"|\")[1].strip())\n",
    "        # Split line with | as separator\n",
    "        topic = lines.split(\"|\")[2]\n",
    "        # Convert to lower case\n",
    "        topic = [x.lower() for x in topic.split()]\n",
    "        # Remove final 's' (assuming it's plural)\n",
    "        # topic = [x.rstrip()[:-1] if (x.rstrip()[-1] == \"s\") else x.rstrip() for x in topic]\n",
    "        # Add to dictionary\n",
    "        topicdict[year] = topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some years had an inclear title, so we hard-code it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicdict[1974] = [\"phytoplankton\",]\n",
    "topicdict[1973] = \"\"\n",
    "topicdict[1972] = [\"Turbulence\", \"mixing\", \"internal\", \"waves\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop on the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on decade 1971 - 1980\n",
      "[('hydrodynamics', 3), ('modelling', 2), ('turbulence', 2), ('marine', 2), ('biochemical', 1), ('state', 1), ('variables', 1), ('evolution', 1), ('equations', 1), ('mathematical', 1), ('sea', 1), ('pollution', 1), ('Turbulence', 1), ('mixing', 1), ('internal', 1), ('waves', 1), ('phytoplankton', 1), ('continental', 1), ('shelf', 1), ('dynamics', 1), ('bottom', 1), ('estuaries', 1), ('fjords', 1), ('forecasting', 1), ('predictability', 1), ('ocean', 1), ('ecohydrodynamics', 1)]\n",
      "\n",
      "Working on decade 1981 - 1990\n",
      "[('hydrodynamics', 3), ('sea', 3), ('modelling', 3), ('ocean', 2), ('coupled', 2), ('ocean-atmosphere', 2), ('marine', 2), ('turbulence', 2), ('ice', 2), ('semi-enclosed', 1), ('equatorial', 1), ('remote-sensing', 1), ('shelf', 1), ('interfaces', 1), ('ecohydrodynamics', 1), ('three-dimensional', 1), ('estuaries', 1), ('dynamics', 1), ('small-scale', 1), ('mixing', 1), ('mesoscale', 1), ('synoptic', 1), ('coherent', 1), ('structures', 1), ('geophysical', 1), ('covered', 1), ('edges', 1), ('physical', 1), ('chemical', 1), ('biological', 1), ('processes', 1), ('interactions', 1)]\n",
      "\n",
      "Working on decade 1991 - 2000\n",
      "[('ocean', 4), ('modelling', 3), ('processes', 3), ('interactions', 2), ('coastal', 2), ('sea', 2), ('marine', 2), ('hydrodynamics', 2), ('ecosystem', 2), ('deep', 1), ('shelf', 1), ('submesoscale', 1), ('air-sea', 1), ('data', 1), ('assimilation', 1), ('science', 1), ('global', 1), ('change', 1), ('perspective', 1), ('regions', 1), ('freshwater', 1), ('influence', 1), ('dominated', 1), ('turbulence', 1), ('revisited', 1), ('ice', 1), ('covered', 1), ('southern', 1), ('northern', 1), ('hemisphere', 1), ('three-dimensional', 1), ('circulation', 1), ('lagrangian', 1), ('measurements', 1), ('diagnostic', 1), ('analysis', 1), ('exchange', 1), ('margins', 1)]\n",
      "\n",
      "Working on decade 2001 - 2010\n",
      "[('sea', 2), ('water', 2), ('use', 1), ('data', 1), ('assimilation', 1), ('coupled', 1), ('hydrodynamics', 1), ('ecological', 1), ('biogeochemical', 1), ('modelling', 1), ('ocean', 1), ('tracer', 1), ('methods', 1), ('geophysical', 1), ('fluid', 1), ('dynamics', 1), ('dying', 1), ('dead', 1), ('marine', 1), ('environments', 1), ('monitoring', 1), ('predictions', 1), ('gas', 1), ('transfer', 1), ('surfaces', 1), ('revisiting', 1), ('role', 1), ('zooplankton', 1), ('pelagic', 1), ('ecosystem', 1), ('turbulence', 1), ('revisited', 1), ('influence', 1), ('climate', 1), ('change', 1), ('changing', 1), ('arctic', 1), ('subarctic', 1), ('conditions', 1), ('science-based', 1), ('management', 1), ('coastal', 1), ('multiparametric', 1), ('observation', 1), ('analysis', 1)]\n",
      "\n",
      "Working on decade 2011 - 2020\n",
      "[('marine', 4), ('environments', 3), ('processes', 2), ('change', 2), ('impacts', 2), ('new', 2), ('ocean', 2), ('tracer', 1), ('physical', 1), ('biogeochemical', 1), ('past', 1), ('ongoing', 1), ('anthropogenic', 1), ('remote-sensing', 1), ('colour', 1), ('temperature', 1), ('salinity', 1), ('challenges', 1), ('opportunities', 1), ('primary', 1), ('production', 1), ('synoptic', 1), ('global', 1), ('scale', 1), ('low', 1), ('oxygen', 1), ('estuaries', 1), ('fresh', 1), ('water', 1), ('monitoring', 1), ('modelling', 1), ('predictions', 1), ('submesoscale', 1), ('mechanisms', 1), ('implications', 1), ('frontiers', 1), ('turbulence', 1), ('revisited', 1), ('long-term', 1), ('studies', 1), ('oceanography', 1), ('celebration', 1), ('50', 1), ('years', 1), ('science', 1), ('liege', 1), ('colloquium', 1), ('polar', 1), ('facing', 1), ('towards', 1), ('understanding', 1), ('assessing', 1), ('human', 1), ('coastal', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for yearmin in range(1971, 2020, 10):\n",
    "    yearmax = yearmin + 10\n",
    "    print(\"Working on decade {} - {}\".format(yearmin, yearmax-1))\n",
    "    topiclistdecade = []\n",
    "    for yyyy in range(yearmin, yearmax):\n",
    "        topiclistdecade.extend(topicdict[yyyy])\n",
    "         \n",
    "    wordstring = \" \".join(topiclistdecade)\n",
    "    wordstring2 = clean_words(wordstring)\n",
    "    \n",
    "    worddict = Counter(wordstring2.split())\n",
    "    sortedworddict = sorted(worddict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    print(sortedworddict)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diva-python3.6",
   "language": "python",
   "name": "diva-python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
